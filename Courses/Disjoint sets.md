# Disjoint sets: Sub-linear time processing // Procesamiento de tiempo sublineal

* Objectives-Goals:
	1. Resolver el problema de mantener un conjunto particionado en conjuntos disjuntos y fusionar las particiones din√°micamente
	2. **Proporcionar una soluci√≥n simple en tiempo lineal para todos los m√©todos**
	3. Mejorar el tiempo de ejecuci√≥n utilizando la estructura de datos subyacente adecuada.
	4. **A√±adir una heur√≠stica f√°cil de implementar para obtener un tiempo de ejecuci√≥n casi constante**
	5. Reconocer los casos de uso en los que se necesita la mejor soluci√≥n para el rendimiento

## El problema de los subconjuntos distintos

Vamos a utilizar un conjunto disjunto cada vez que queramos realizar una partici√≥n de un conjunto inicial(Universo) de objetos en grupos disjuntos.
 
Un conjunto disjunto es aquel que no comparte elementos con alg√∫n otro conjunto del universo, teniendo as√≠ subconjuntos de este sin ning√∫n elemento del universo en com√∫n entre ellos.

**image**

Una analog√≠a que nos puede ayudar a entender el problema ser√≠a ver los conjuntos disjuntos como las recomendaciones no personalizadas. ¬øPor qu√©?

Porque seguramente alg√∫na vez han escuchado sobre las recomendaciones personalizadas, pero que s√≥n? 

Las recomendaciones personalizadas es eso que hacen las grandes corporaciones para mantener el m√°ximo tiempo posible consumiendo su contenido, son esas que se dirigen a clientes individuales a partir de la informaci√≥n y/o datos previamente conocidos como compras anteriores o metadatos que muestran similitudes con otros usuarios, es por eso que las recomendaciones que me salen a m√≠ cuando veo YT no son las mismas que las que le podr√≠an salir a un ni√±o, un maestra o incluso ustedes, porque evidentemente no todos tenemos los mismos intereses. 

Mientras que las recomendaciones no personalizadas  son aquellas que no se dirigen a t√≠ o alguien en particular, si no a todos los consumidores o clientes en general, si no tenemos ning√∫n dato podemos hacer las asociaciones codificadas por nosotros mismos como desarroladores(fuerza bruta) o basadas en acciones realizadas por otros clientes.

Para simplificar las cosas imaginemos que la regla establecida es que si un art√≠culo X y el art√≠culo Y se compran juntos m√°s de un umbral fijo durante la √∫ltima hora, sus respectivas categor√≠as(2) se fusionan.

Por ejemplo, si un cliente compra un producto X, en eso momento podr√≠amos sugerirle un art√≠culo al azar de la misma categor√≠a. 

Este proceso descrito es bastante com√∫n en la ciencia de los datos. Algunos de ustedes habr√°n reconocido esto y es que no es nada menos que la agrupaci√≥n jer√°rquica(hierarchical clustering). Obviamente esto es m√°s complejo de lo que 

// In a real non-personalized recommender system, we would track associations between products, measuring the strength of the link as the confidence that when X is bought, Y is also. . Para ello, podemos calcular el n√∫mero de compras en las que aparecen ambos, dividido por el n√∫mero total de compras en las que aparece al menos Y. Eso nos dar√≠a una mejor idea de qu√© va con qu√©, podr√≠amos definir un umbral de confianza para fusionar los grupos, y en lugar de elegir de la confianza para fusionar los grupos, y en lugar de elegir un art√≠culo al azar en el mismo grupo, mostrar las cinco asociaciones m√°s fuertes.

El punto de partida es que tenemos que partir de este enorme conjunto de elementos y dividirlos en grupos separados, en grupos disjuntos. Y por supuesto, se pueden a√±adir nuevos elementos al cat√°logo todo el tiempo y las relaciones son din√°micas, por lo que tendremos que ser capaces de actualizar tanto la lista de art√≠culos como los grupos.

* Un ejemplo r√°pido que podemos ver de una aplicaci√≥n de un conjunto disjunto.
	
	1. En este escenario, tenemos un sitio web de comercio electr√≥nico que intenta comprender qu√© productos se venden bien juntos, para poder ofrecer mejores recomendaciones a sus clientes. 

	2. (B) Al inicio tendremos que cada art√≠culo en venta est√° en su propia categor√≠a, una categor√≠a diferente. 
		- Esto tambi√©n funcionar√≠a si parti√©ramos de categor√≠as ya predefinidas, como discos SSD o batidoras, y agrup√°ramos las categor√≠as de objetos que se venden juntos. 

		Pero en aras de la simplicidad, tened paciencia conmigo e imaginad que s√≥lo hay un producto de cada categor√≠a a la venta. 

	3. (C) Despues de unas ventas, agruparemos los objetos que se compran juntos con frecuencia, como los ordenadores port√°tiles y los discos externos, o las raquetas de tenis y las pelotas de tenis. 

	4. (D) Para que despu√©s de un tiempo, las cosas tienden a estabilizarse y se forman categor√≠as-grupos estables. Para que la pr√≥xima vez que un cliente a√±ada una computadora a su carrito, podremos sugerirle un par de objetos m√°s relacionados con su compla como un celular.

## Reasoning on solutions

Antes de abordar nuestra posible soluci√≥n es importante mencionar que nos limitaremos al caso agregativo, ¬øQu√© significa esto? Que dos particiones (conjuntos disjuntos) pueden fusionarse en un conjunto m√°s grande pero no lo contrario. Osea que una partici√≥n no puede dividirse en dos subconjuntos.

Dependiendo del tama√±o del cat√°logo, podr√≠amos incluso encajar una estructura de datos de este tipo en la memoria, pero vamos a suponer, en cambio, que configuramos un servicio REST basado en un almacenamiento persistente tipo Memcached(Un almac√©n de claves-valores (no-SQL) utilizado como sistema de cach√© de objetos distribuidos.). 

La durabilidad de los datos es importante en este caso, porque en nuestro ejemplo, la actividad de seguimiento de los art√≠culos durar√° a√±os, y no queremos volver a calcular toda la estructura de conjuntos disjuntos cada vez que haya un cambio o se a√±ada un nuevo producto. Por lo que buscamos persistencia de nuestros datos y esto puede ser atraves de una librer√≠a o un Rest CLient:

https://duckduckgo.com/?q=underlying+data+structure&t=newext&atb=v311-1&ia=web

### API

#### Description

Un posible dise√±o para una aplicaci√≥n que utilice esta estructura: disjoint set. El **Disjoint Set Client** puede ser cualquier cosa, desde una biblioteca hasta un cliente REST. 

El prop√≥sito del cliente (delgado) aqu√≠ es ser una interfaz entre el almacenamiento en memoria (el nodo Memcached en la imagen) y el servidor, que tiene almacenamiento persistente. 

El servidor puede ser un servidor web, pero tambi√©n podr√≠a ser simplemente otra aplicaci√≥n (nativa) que almacena datos en un disco. 

* El Disjoint Set Client(cliente del conjunto disjunto) se ejecutar√° en la misma intranet, posiblemente incluso en la misma m√°quina, que el servidor de comercio electr√≥nico. 

	- Este tendr√° un trabajo cron(que permitre la sincronizaci√≥n) para mantener el almacenamiento persistente sincronizado con la versi√≥n en memoria (esto podr√≠a ocurrir cada pocos segundos o de forma as√≠ncrona despu√©s de cada operaci√≥n). 

	- Y adem√°s, responder√° a las llamadas del sitio de comercio electr√≥nico, consultando el almacenamiento en memoria cuando sea necesario, llamando al servidor web
		- No (y, en caso de que no quepan todos los datos en la memoria, tambi√©n se encargar√° del swap).

## Describing the data structure API: Disjoint set

Como se podran imaginar tendremos una clase que nos permitira representar nuestra estructura de datos.

- **Slide 6** Ocupamos las operaciones en nuestra API:  

	+ _init(U)_: La inicializaci√≥n s√≥lo se encarga de la asignaci√≥n de los campos b√°sicos que necesita la clase y asigna cada elemento a su propia partici√≥n.
	+ _findPartition(x);_  Si x pertenece al universo U regresamos la partici√≥n a la que pertenece.
	+ _merge(x, y)_;, Dados dos elementos _x_,_y_ del universo, fusiona sus particiones en una sola.
	+ _areDisjoint(x,y)_; Dados dos elementos _x_,_y_ del universo, nos dice si estos pertenecen a diferentes particiones.

- Contrato con el cliente: Es decir, lo que tenemos que **TENER PRESENTE**.

	1. Un conjunto disjunto guardara las relaciones mutuas entre los elementos del universo U. 
	2. La relaci√≥n esta definida por el cliente, osea que la relaci√≥n no est√° definida expl√≠citamente por la estructura de datos.
	3. Por ultimo, se asume que dicha relaci√≥n ¬Æ tiene las propiedades reflexiva, sim√©trica y transitiva
esto significa que dados los elementos x, y, z de U

- Restricciones:

	- Sin p√©rdida de generalidad, podemos limitarnos al caso en que el Universo U, es decir, el conjunto de todos los elementos posibles, es conocido de antemano y est√°tico. 
	- Tambi√©n asumimos que inicialmente cada elemento est√° en su propia partici√≥n. 
	- Asumimos que los elementos de nuestro Universo U son los enteros entre 0 y n-1. 
		* /// Esto no es una restricci√≥n real, porque podemos asociar f√°cilmente un √≠ndice a cada uno de los elementos reales de U.

/// Las soluciones para soportar las violaciones de estas suposiciones se pueden conseguir f√°cilmente haciendo un uso inteligente de las matrices din√°micas y de los propios m√©todos de la clase.

- Las garant√≠as que ofrece la clase son:
	1. Es posible a√±adir una relaci√≥n entre dos elementos cualesquiera.
	2. Si dos elementos en un punto cualquiera se fusionan (es decir, se a√±ade una relaci√≥n entre ellos), estos formar√°n parte del mismo conjunto disjunto.
	3. Si hay una cadena de elementos x1 , x2 , ..., xn tal que x1 se ha fusionado con x2 , x2 se ha fusionado con x3 y as√≠ sucesivamente, entonces x 1 y x n estar√°n en la misma partici√≥n.
		- Si tenemos los elementos x1,x2,...,xn, si x1 se fusiona con x2, x2 con x3, y as√≠ sucesivamente, entonces al final tendr√≠amos que todos los elementos estar√°n en la misma partici√≥n
	4. Si dos elementos no est√°n en la misma partici√≥n, entonces no existe otro elemento que pertenezca a los conjuntos disjuntos de ambos elementos.

// 

* La lectura y yo buscamos es que no seas la persona que diga: "¬°Bueno, eso es f√°cil! Se mantiene un array para cada subconjunto(un array din√°mico o un vector). ¬øPor qu√© se preguntaran? 
	
	- No, porque al usar arrays, hay que entender si dos elementos est√°n en el mismo conjunto podr√≠a requerir potencialmente recorrer todos los elementos de todos los subconjuntos. Del mismo modo, para saber a qu√© subconjunto pertenece un elemento podr√≠a requerir el mismo n√∫mero de comprobaciones de elementos; es decir, la b√∫squeda podr√≠a ser lineal en el n√∫mero total de elementos, lo cual es extremadamente lento y no estamos en la paradoja de la tortuga y alquimides, por lo que podremos mejorar el tiempo lineal.

	La siguiente idea en esta lluvia de ideas podr√≠a consistir en a√±adir un mapa de elementos a subconjuntos, junto con la lista de subconjuntos explicada anteriormente. Esto es una mejora ligeramente mejor para algunas operaciones; aunque, como veremos, todav√≠a obliga a que operaciones como la fusi√≥n de dos conjuntos requieran potencialmente asignaciones O(n). Sin embargo, el rendimiento no es la principal preocupaci√≥n de este dise√±o sino que usar dos estructuras de datos independientes es una idea terrible ya que tendr√≠amos que sincronizarlas manualmente cada vez que te enfrentes a este problema en tu aplicaci√≥n. Y esto es muy propenso a errores. 

	> Una soluci√≥n ya mejor es proporcionar una clase envolvente que utilice internamente esas dos estructuras: te da encapsulaci√≥n y aislamiento y, como resultado, eres capaz de escribir s√≥lo una vez el c√≥digo que sincroniza ambas estructuras en, digamos, a√±adir o fusionar (y as√≠ ganas reusabilidad). Y lo que es m√°s importante, puedes probar tu clase de forma aislada y, por lo tanto, tener una garant√≠a razonable de que va a hacer su trabajo sin experimentar errores cada vez que la utilices en tu aplicaci√≥n (es decir, siempre que escribas pruebas unitarias buenas y exhaustivas, que superen los casos l√≠mite y desaf√≠en el comportamiento de tu clase en todos los contextos posibles).

	Necesitaremos escribir una clase que se encargue de todo el problema, llevando la cuenta de a qu√© subconjunto (disjunto) pertenece un elemento, y encapsulando toda la l√≥gica en ella. Sin embargo primero tenemos que hablar sobre la durabilidad de nuestros datos ya que es importante en este caso.

## Na√Øve solution A

La soluci√≥n m√°s rapida que podemos implementar es representar cada partici√≥n como una lista ligada,  por c/elemento en nuestro arreglo necesitaremos mantener la pista del apuntador de la cabeza de la lista.

Para verificar que dos elementos esten en la misma partici√≥n solo necesitamos revisar si los dos est√°n en la misma lista

Para fusionar 2 particiones solo actualizamos el ultimo apuntador de una lista a la cabeza de la otra lista:

* Digamos P1, P2 representados por l1,l2, solo necesitamos actualiar el _next pointer_ del √∫ltimo elemento de l1 para que apunte a la cabeza de l2(o viceversa)
	
	- Podemos hacer esta operaci√≥n en tiempo constante manteniendo un puntero extra a la cola de la lista 
		- Sin embargo para cada elemento de L2 , tambi√©n tenemos que actualizar su puntero de lista en nuestro mapa para que apunte a la cabeza de la nueva lista combinada.

		- Sin embargo, desafortunadamente el peor de los casos de esta operaci√≥n toma tiempo lineal ya que tendr√≠amos que actualizar el puntero de la lista en nuestro mapa para que apunte a la cabeza de la nueva lista generada por la fusi√≥n de n-1 elementos.

			- Se podr√≠a mejorar este tiempo a√±adiendo siempre la lista m√°s corta pero esto solo nos asegurar√≠a que no tendr√≠amos que actualizar n/2 punteros de elementos, pero esto no mejora el tiempo de ejecuci√≥n asint√≥tico.

	- **image**  A la izquierda: una de las dos listas se anexa a la otra a√±adiendo un nuevo y eliminando enlaces de la matriz a la segunda lista. A la derecha se muestra el resultado tras la fusi√≥n, con todos los punteros de los elementos de la matriz que pertenecen a la lista a√±adida (elementos 1 y 5 en el ejemplo) actualizados. ejemplo) actualizados.

* Clase DisjointSet tendra como atributo un HashMap que puede tener como llaves los elementos y como los valores tendremos las listas de elementos.

* M√©todos de la clase:

	- Constructor: 

		+ Este m√©todo toma como par√°metro la lista(o algo iterable) de los elementos que conformar√°n nuestro conjunto.
		+ Creamos un nuevo mapa para todos los conjuntos como elementos.
		+ Por cada elemento en la lista verificamos que no sea un null o un elemento que previamente ha sido agregado(repetidos) a nuestro mapa, para mapear el elemento con un nuevo conjunto unitario que solo contiene dicho elemento (inicialmente cada elemento es disjunto de cualquier otro elemento).
			- **Es importante notar que lanzaremos una excepci√≥n en caso de que:**
				1. El elemento por insertar es null
				2- El elemento por insertar no sea repetido
		+ // we can add a size public property, simply defined as the number of entries stored in the local partitions map.

	Como podremos ver la inicializaci√≥n es facil ya que solo comprobaremos que la lista pasada como argumento no contiene duplicados e inicializaremos el conjunto disjunto con sus elementos, solo inicializamos el mapa(array asociativo) que va a indexar los elementos y los asignamos a la partici√≥n a la que pertenecen.

	Y podemos ver que esto se hace en tiempo lineal ya que tenemos que hacer esto por todos los elementos de nuestra lista.

	- add: Podemos ocupar agregar nuevos elementos a nuestro universo _add_, para ello este m√©todo, por cada elemento que queramos agregar solo creamos una nueva partici√≥n que contenga solo este elemento.

		+ Dado un elemento _elem_ regresa T syss este elemento pudo agregarse exitosamente, F en otro caso.
		+ Verifica que _elem_ no sea nulo o que sea un elemento repetido, es decir, que ya est√© en nuestro mapa, si pasa algo de esto regresa F.
		+ Por √∫ltimo crea un nuevo conjunto unitario con este elemento y lo mapea a este elemento, para regresar T.

	This method is used to allow the Universe to grow, with new (unique) elements that can be added at any time. Every time we add a new element, we just add a brand-new partition containing that element alone

	- findPartition: 

		+ Dado un elemento regresa el conjunto(la partici√≥n, disjoint set) al que pertenece
		+ Verificamos que el elemento sea valido, es decir que no sea null o que previamente haya sigo agregado.
			- **Es importante notar que lanzaremos una excepci√≥n en caso de que pase esto.**
		+ Regresa el conjunto que contiene el elemento que recibimos como entrada

	En esta implementaci√≥n este m√©todo solo toma tiempo constante(assuming that the hash for elem can be computed in constant time), realmente es un m√©todo muy sencillo

	- areDisjoint(elem1,elem2): 

		+ Dados dos elementos regresamos T syss los elementos son v√°lidos y no pertenecen a la misma partici√≥n
			- regresa F syss los elementos son v√°lidos y pertenecen a la misma partici√≥n

	Es un m√©todo muy sencillo ya que solo necesitamos ocupar nuestro m√©todo findPartition previamente implementado, para obtener el conjunto disjunto de cada p√°rametro. 

		+ (Haciendo esto nos podremos asegurar que la implementaci√≥n no necesitar√° cambiar, no importa c√≥mo se almacenen nuestros elementos o se implemente findPartition (siempre que su interfaz siga siendo la misma, y las particiones puedan compararse con el operador de desigualdad).

	Es **importante** saber que se implementa esta comprobaci√≥n para los elementos que pertenecen a diferentes en lugar de los elementos que pertenecen a la misma porque es la forma en que se utilizan normalmente(los conjuntos disjuntos). Ya que nos interesa comprobar si dos elementos no pertenecen a la misma partici√≥n, para saber si fusionamos las dos particiones o no.

	> *Todos los m√©todos que hemos visto hasta ahora se ejecutan en tiempo constante con respecto al tama√±o del del contenedor.*

	- merge: Como hemos visto, el m√©todo de fusi√≥n requiere O(n) asignaciones en el peor de los casos.

		+ Dados dos elementos, regresamos T si se se pudieron fusionar las particiones a las que pertenecen o F si estos ya estaban en la misma particion.

			- Primero comprobamos si los elementos pertenecen a la misma partici√≥n llamando a findPartition en ambos y comprobando el resultado. Obteniendo las particiones a las que pertenecen los elementos que recibimos como parametros.
			- Checamos si son la misma, para regresar false ya que en realidad ya estaban en la misma partici√≥n
			- Por cada elemento en el primer lista/conjunto:
				1. Lo agregamos a la otra lista/conjunto, corrigiendo/actualizando los punteros **en el mapa** de particiones.
			- Regresamos T

		* Para hacer merge:
			- Si las particiones estuvieran implementadas con listas enlazadas en lugar de conjuntos, podr√≠amos haber a√±adido simplemente la cabeza de una lista a la cola de la otra. Sin embargo, los conjuntos nos obligan a a√±adir elementos uno a uno. Se necesita un n√∫mero lineal extra de asignaciones (en el peor de los casos), pero esto no cambia el orden de ejecuci√≥n de la funci√≥n; a√∫n necesitamos actualizar las referencias de los elementos de una de las dos listas (es decir, los conjuntos) de todos modos

* https://github.com/mlarocca/AlgorithmsAndDataStructuresInAction/blob/master/JavaScript/src/disjointset/variants/disjointset_lists.js

## Using a tree-like structure

La idea es simple, en lugar de usar listas usaremos √°rboles, cada partici√≥n se identifica de forma √∫nica por la ra√≠z del √°rbol asociado a la partici√≥n.

Cada partici√≥n se identificara de forma √∫nica por la ra√≠z del √°rbol asociado a la partici√≥n. La ventaja de los √°rboles sobre las listas es que si el √°rbol est√° equilibrado, cualquier operaci√≥n sobre el √°rbol es logar√≠tmica! Lo que es mejor que el tiempo lineal que ten√≠amos.

Los √°rboles llevan el nombre de su ra√≠z, porque utilizamos la ra√≠z del √°rbol como identificador √∫nico de la partici√≥n 

Cada elemento del mapa(de la matriz) apunta a un nodo del √°rbol: en la implementaci√≥n ingenua ten√≠amos un mapeo 1:1 entre los elementos y los nodos del √°rbol. Esto significa que para llegar a la ra√≠z del √°rbol posiblemente tengamos que escalar todo el √°rbol (y, en promedio, la mitad de la altura del √°rbol)

Para fusionar dos conjuntos cuando se utiliza la representaci√≥n en √°rbol. S√≥lo es necesario crear un nuevo enlace (adem√°s de recorrer un poco el √°rbol). En la figura de la izquierda, a√±adimos una arista desde la ra√≠z del √°rbol 1 a la ra√≠z del √°rbol 0, para fusionarlos. A la derecha, mostramos c√≥mo esto cambia la estructura de datos: ahora s√≥lo tenemos dos √°rboles, pero la altura del √°rbol 0 es ahora mayor que antes de la fusi√≥n.

- Esto representa una gran mejora respecto a la soluci√≥n ingenua, ya que no tendremos que actualizar el mapa de particiones para ninguno de los otros elementos de las particiones fusionadas. 

	- En su lugar cada nodo del √°rbol mantendr√° un enlace a su padre (no necesitamos guardar enlaces a hijos, porque no son √∫tiles en este caso).

Como las particiones se  identifican de forma √∫nica por las ra√≠ces del √°rbol entones al averiguar a qu√© partici√≥n pertenece un elemento, solo hay que recuper el nodo del √°rbol al que apunta y subimos hasta la ra√≠z de su √°rbol. En el m√©todo areDisjoint, hacemos lo mismo para ambos elementos para comparar las ra√≠ces encontradas y as√≠ poder ver si los dos elementos pertenecen a la misma partici√≥n (si y s√≥lo si las dos ra√≠ces son iguales).

* En merge, es decir, la fusi√≥n de dos particiones requiere ahora un n√∫mero constante de cambios, m√°s el n√∫mero de b√∫squedas necesarias para encontrar las dos ra√≠ces. 
	- Por lo que encontrar el conjunto al que pertenece un elemento requiere un tiempo logar√≠tmico de media pero tiempo lineal en el peor de los casos, es decir, cuando tenemos que la altura del √°rbol es n, el n√∫mero total de elementos que tenemos

Esto se debe a que, al fusionar particiones, podemos tener mala suerte con la elecci√≥n de la ra√≠z del √°rbol que ponemos como hijo de la otra. Al elegir aleatoriamente cada vez qu√© ra√≠z se va a utilizar como hijo de la otra, podemos hacer que este escenario del peor caso sea poco probable... pero todav√≠a ser√≠a posible (aunque extremadamente desafortunado). 

Esto significa que la implementaci√≥n en nuestro peor escenario de merge todav√≠a requiere tiempo O(n), lo cual no es bueno.

### Implementing the tree version - Page 14

Cambiaremos el nombre del mapa:partitionsMap a parentsMap, para que no haya pierde y en lugar de mapear a un conjunto real, los elementos del mapa de partici√≥n apuntan al padre de cada elemento en el √°rbol. 

Adem√°s en la inicializaci√≥n, estableceremos convenientemente cada elemento como su propio padre.

The same change applies to the add method, which otherwise stays unchanged.

* UTILIZANDO √ÅRBOLES: findPartition: 
	- Sera un m√©todo que toma un elemento y devuelve el elemento que est√° en la ra√≠z del √°rbol para la partici√≥n a la que pertenece elem
	- Despu√©s de obtener el padre del elemento, comprobamos si es el mismo(propio) elemento. 
		- Porque si un elemento es su propio padre, entonces sabemos(eso significa) que hemos llegado a la ra√≠z del √°rbol de la partici√≥n, debido a la forma en que inicializamos este campo(la ra√≠z tiene como padre el mismo) y porque en merge nunca cambiamos el padre de una ra√≠z.
		- Si no, seguimos iterando hasta llegar a la ra√≠z.
	Se podr√≠a decir que con la recursi√≥n recorremos todo el √°rbol hasta llegar la ra√≠z

- Esta nueva implementaci√≥n de findPartition, ya no se ejecuta en tiempo constante ya que tendremos tantas llamadas recursivas como la altura del √°rbol de la partici√≥n. 
	- Como hasta ahora no podemos hacer ninguna suposici√≥n sobre los √°rboles, esto significa que posiblemente tengamos un n√∫mero de llamadas proporcional al n√∫mero de elementos del Universo U, aunque esto es el peor de los caso, en promedio podemos esperar un rendimiento mucho mejor. 

- Y aunque ahorita parecer que s√≥lo hemos empeorado el rendimiento de nuestra estructura de datos ya que pasamos de tiempo constante a una logaritmica aun hay que ver nuestra nueva implementaci√≥n de la operaci√≥n de fusi√≥n.

/// - Se establece el padre de p2 para que sea igual a p1 , de modo que ahora tanto p1 como p2 tienen el mismo padre, pero tambi√©n todos los elementos de p2 compartir√°n finalmente p1 como ra√≠z de su √°rbol

- Comparando las dos implementaciones se puede ver inmediatamente que √©sta es m√°s sencilla, s√≥lo hemos cambiado las √∫ltimas l√≠neas. Sin embargo ya no necesitamos iterar por una lista de elementos, si no que para fusionar  sus dos particiones, simplemente tenemos que llegar a ra√≠ces de ambos √°rboles, y luego establecer una ra√≠z como el padre de la otra. 
	- Todav√≠a tenemos que encontrar las ra√≠ces de los √°rboles

- Como la nueva l√≠nea que hemos a√±adido s√≥lo requiere un tiempo constante, entonces el tiempo de ejecuci√≥n del m√©todo dependera de las dos llamadas a findPartition y como hemos visto, requieren un tiempo proporcional a la altura del √°rbol sobre el que son llamadas, y en el peor de los casos esto puede seguir siendo lineal. Sin embargo, esto solo pasa en el caso medio, y especialmente en las primeras etapas tras la inicializaci√≥n, despues de esto, sabemos que la altura de los √°rboles ser√° mucho menor.

- Conclusi√≥n; Tenemos un conjunto disjunto para el que todas las operaciones siguen requiriendo tiempo lineal en el peor de los casos, pero en promedio s√≥lo necesitar√°n tiempo logar√≠tmico, incluso para aquellas operaciones que eran de tiempo constante en la implementaci√≥n ingenua.
	-  Si lo miramos desde una perspectiva diferente, ya hemos conseguido tener un conjunto de operaciones m√°s equilibrado en nuestro conjunto disjunto, lo que es especialmente bueno en aquellos contextos en los que la fusi√≥n es una operaci√≥n com√∫n.

Pero esto no es todo, la cosa puede mejorar :D

### Heuristics to improve the running time 13

El siguiente paso en nuestra b√∫squeda de un rendimiento √≥ptimo es asegurarnos de que findPartition sea logar√≠tmica incluso en el peor de los casos.

Podemos llevar f√°cilmente la cuenta del rango (tambi√©n conocido como tama√±o) de cada √°rbol, utilizando espacio lineal extra y realizando operaciones extra en tiempo constante en nuestro m√©todo merge, solo actualizaremos el rango s√≥lo para las ra√≠ces de los √°rboles y cuando fusionemos dos √°rboles solo nos aseguraremos de establecer como hijo el √°rbol con el menor n√∫mero de nodos. (menor rango)

* Y se puede demostrar por inducci√≥n que este √°rbol ser√° tambi√©n el que tenga la menor altura: esto significa que el nuevo √°rbol tendr√° la misma altura que el anterior, o simplemente tendr√° su altura incrementada en 1.
	- Tambi√©n se puede demostrar que la altura de un √°rbol no puede incrementarse m√°s que un n√∫mero logar√≠tmico de veces. Y como un logaritmo crece muy lentamente (por ejemplo ln(1000) ~= 10, ln(1000000) ~= 20) , esto es, en la pr√°ctica, ya un buen resultado, suficiente para la mayor√≠a de las aplicaciones. Sin embargo, recordemos que algunas veces buscamos hacer las cosas le mejor posible como cuando est√°s escribiendo alg√∫n c√≥digo central realmente cr√≠tico, como un kernel o c√≥digo de firmware 0.0 
		- ¬øPor qu√©? Porque puedes. Y a veces tambi√©n porque es necesario. Si ahorras 0,001 ms en una operaci√≥n que repetir√°s mil millones de veces, ya habr√°s ahorrado 16 minutos de c√°lculo.

#### $ Comprensi√≥n de rutas $

* Podemos hacer algo mejor que solo tener √°rboles equilibrados y m√©todos de tiempo logar√≠tmico. Para mejorar a√∫n m√°s nuestros resultados, podemos utilizar una heur√≠stica llamada compresi√≥n de rutas.
	
	- Para cada nodo de los √°rboles, en lugar de almacenar un enlace a su padre, podemos almacenar uno a la ra√≠z del √°rbol. 
		- Total, no necesitamos llevar un historial de las fusiones realizadas ya que s√≥lo necesitamos saber en el momento actual cu√°l es la ra√≠z de la partici√≥n de un elemento
			- **S√≥lo ocupamos** saber en el momento actual cu√°l es la ra√≠z de la partici√≥n de un elemento, y averiguarlo tan r√°pido como podamos.

	- Imagen: Conjunto disjunto representado mediante un √°rbol con compresi√≥n de trayectoria. La representaci√≥n interna se muestra junto a la matriz de elementos. En la representaci√≥n del √°rbol, las flechas discontinuas son enlaces de padres, mientras que las flechas s√≥lidas son punteros a la ra√≠z del conjunto. La estructura contiene inicialmente dos conjuntos, coloreados en rojo claro y azul oscuro y cuyas ra√≠ces son respectivamente 0 y 1.

* !Es importante!, si se actualizaran todos los punteros ra√≠z como parte de la fusi√≥n, ya no ser√≠a un m√©todo logar√≠tmico; necesitar√≠amos un tiempo lineal para actualizar cada nodo del √°rbol. 

### Imagen of deprecated

* ¬øQu√© ocurre si no actualizamos inmediatamente los punteros padre en los nodos del √°rbol establecidos como hijo? Sencillamente, la pr√≥xima vez que se ejecute findPartition en uno de los elementos de ese √°rbol digamos x, tendremos que recorrer el √°rbol desde x hasta su primera(antigua) ra√≠z xR  y luego desde xR hasta la nueva ra√≠z R del arbol(nuevo) completo

* Hay que tener en cuenta que los punteros de los elementos del √°rbol antiguo podr√≠an haber estado sincronizados antes de la fusi√≥n o podr√≠an no haberse actualizado nunca. Como de todos modos tendremos que subir por el √°rbol, podemos volver sobre nuestros pasos desde la cima, R , hasta x y actualizar los punteros de la ra√≠z para todos esos elementos. 

* Sin embargo, esto no influir√° en nuestro rendimiento asint√≥tico para findPartition , ya que al volver a recorrer el mismo camino s√≥lo duplicamos el n√∫mero de pasos y sabemos que los factores constantes son irrelevantes en el an√°lisis asint√≥tico.

* descripcion imagen: Por ejemplo, en la imagen, podemos observar que el √°rbol azul oscuro est√° desincronizado. Si llamamos a find sobre el elemento 6 , el algoritmo empieza a subir lentamente por el √°rbol azul, hasta que nos encontremos con su ra√≠z (tercer diagrama).  
(diagramas inferiores), para que el algoritmo retroceda, y actualice la ra√≠z para los elementos intermedios 9 y 6 previamente encontrada.

Y como consecuencia de estos pasos extra, ent tendremos en la pr√≥xima vez que llamemos a findPartition necesitaremos un √∫nico paso para encontrar su ra√≠z **//** Ya que en cualquier elemento de la ruta desde x hasta root(x) podremos saber con seguridad que esos punteros estar√°n actualizados y por ende solo necesitaremos un √∫nico paso para encontrar su ra√≠z.

* Nos gustar√≠a saber cu√°ntas veces tendremos que actualizar los punteros ra√≠z, en promedio, para una sola operaci√≥n o, en un an√°lisis amortizado, durante un cierto n√∫mero k de operaciones pero esto ya se pone oscuro, entonces 

	* S√≥lo hay que saber que se ha demostrado que el tiempo de ejecuci√≥n amortizado para **_m_** llamadas a findPartition y merge sobre un conjunto de **_n_** elementos requerir√° **_n O(m * Ack(n))_** accesos al array.

	Y **_Ack(n)_** es una aproximaci√≥n de la funci√≥n inversa de Ackermann y esta funci√≥n crece tan lentamente que puede considerarse una constante ya que su valor ser√° inferior a 5 para cualquier n√∫mero entero que pueda almacenarse en un ordenador.

		-  Todav√≠a no se sabe si este es el l√≠mite m√°s bajo para la estructura de datos Union-Find. Sin embargo, se ha demostrado que O(m * InvAck(m, n)) es un l√≠mite inferior estricto, donde InvAck(m, n) es la verdadera funci√≥n inversa de Ackermann.

	- üèÜ **logramos obtener un l√≠mite constante amortizado para todas las operaciones en ¬°esta estructura de datos!** üèÜ

* Y aunque esto √∫ltimo suene d√≠ficil, s√≥lo necesitamos unos peque√±os cambios para implementar la heur√≠stica de compresi√≥n del camino.


### Implementaci√≥n balanceada con la compresi√≥n de la ruta

Ahora discutiremos la implementaci√≥n final de nuestra estructura de conjuntos disjuntos, incluyendo tanto la heur√≠stica de "equilibrio de √°rboles por rango" como la de "compresi√≥n de rutas".

* Ocupamos la clase info que guarda el rango y la raiz para simular nuestra comprensi√≥n de ruta
	
	- Esta clase Info modela (la informaci√≥n asociada a) un nodo del √°rbol de particiones. Es s√≥lo un contenedor para dos valores: la ra√≠z del √°rbol y el rango (es decir tama√±o) del √°rbol enraizado en el elemento actual.
	
	- En la propiedad ra√≠z no almacenaremos referencias a otros nodos. En su lugar, almacenaremos directamente el (√≠ndice del) propio elemento, que luego utilizaremos como clave de un HashMap , exactamente como hemos mostrado en las secciones anteriores.
	
	- **Lectura: Ahora** Si realmente estuvi√©ramos modelando una estructura de datos en forma de √°rbol, este dise√±o resultar√≠a en una encapsulaci√≥n imperfecta. Pero s√≥lo estamos utilizando la clase Info como una tupla para reunir todas las propiedades asociadas a un elemento. 

* La mayor√≠a de las implementaciones de conjuntos disjuntos utilizar√≠an dos matrices para esto. Dado que nuestra implementaci√≥n no restringe las claves a enteros y estamos usando mapas hash, podr√≠amos definir dos Mapas para las ra√≠ces y rangos del elemento. 
	- Al hacerlo, sin embargo, almacenar√≠amos cada elemento tres veces: dos veces como clave de cada mapa y una vez como ra√≠z de alg√∫n √°rbol (esta √∫ltima entrada podr√≠a almacenar, por supuesto, algunas claves varias veces y otras no). 

Al utilizar este wrapper(esta envoltura) adicional y un √∫nico mapa de "informaci√≥n", nos aseguramos de almacenar los elementos s√≥lo una vez como claves y no m√°s veces

Mientras que los objetos se almacenar√≠an como referencia, con una sobrecarga m√≠nima, valores inmutables, y especialmente  cadenas, se almacenar√≠an por valor. E incluso evitar almacenar cada elemento una vez m√°s puede conducir a un ahorro de memoria consistente. 

* En teor√≠a, podr√≠amos hacerlo a√∫n mejor almacenando cada elemento en envolturas de objetos y utilizando esas mismas envolturas como claves. As√≠ s√≥lo almacenar√≠amos cada clave una vez, y utilizar√≠amos las referencias de los wrappers todo el tiempo, tanto como claves para nuestro(s) mapa(s) como para los valores. 

* Digo en teor√≠a porque tendr√≠as que preguntarte, si ¬øMerece la pena la sobrecarga y el aumento de complejidad de la soluci√≥n de las envolturas? 

	- Esto depende de las suposiciones que puedas hacer sobre el tipo y el tama√±o de las claves. En la mayor√≠a de los casos, probablemente no, as√≠ que aseg√∫rese de perfilar adecuadamente su aplicaci√≥n y analizar su entrada antes de embarcarse en tales optimizaciones. 

* **Estando en la 19 Vuelves a la diapositiva 9** Volviendo a nuestra implementaci√≥n: una vez m√°s, los cambios son m√≠nimos. Tanto en el constructor como en add , s√≥lo tenemos que actualizar la √∫ltima l√≠nea: Cambiando el conjunto unitario por el constructor de la clase Info.
	
	- partitionsMap[elem] = new Set(elem) por parentsMap[elem] = new Info(elem). Usando el constructor  de nuestra clase Info para crear una nueva instancia y asociarla con cada elemento.

* **Estando en la 19** findPartition: 5.9: Como mencione previamente(se describi√≥ al principio de la secci√≥n), cuando se utiliza la heur√≠stica de compresi√≥n de rutas, no actualizamos la ra√≠z de todos los elementos en merge.
	
	- Pero s√≠ la actualizamos en findPartition. As√≠, la principal diferencia con la versi√≥n anterior es que guardamos el resultado de las llamadas recursivas a findPartition en la l√≠nea #6, y lo usamos para actualizar la ra√≠z del elemento actual. Todo lo dem√°s permanece exactamente igual.

		- info.root ‚Üê this.findPartition(info.root)

* **Estando en la 20** La mayor parte del cambio surge en el merge:	

	- Toma dos elementos, regresa T syss pueden fusionarse las dos diferentes particiones de los elementos recibidos como p√°rametros, y false en caso de que est√©n en la misma particion.

	- #1,2 Obtenemos las raices de particiones a las cuales pertenecen, si algo pasa mal con los elem1 se lanzara una excepcion
	- verificamos que no esten en la misma partici√≥n #3
		- porque si ya est√°n en la misma no hace falta hacer la fusion
	- **#5,6: Los 2 info_i** como no est√°n en la misma obtenemos la info de cada nodo para poder realizar la fusion, por lo que busca los nodos de informaci√≥n para ambas ra√≠ces.
	- **#5,6: >=** Checamos quien en el arb√≥l con el rango-rank m√°s grande para que el √°rbol m√°s peque√±o se convierta en un subarbol del otro para
		- actualizar los datos: el rank y la raiz 
			- No vale la pena actualizar el rango de la otra (antigua) ra√≠z, porque nunca se volver√° a comprobar

* Seguimos recuperando los elementos de las ra√≠ces de los √°rboles como antes, y seguimos comprobando que no son los mismos. Pero despu√©s de eso, tenemos que recuperar la informaci√≥n de ambas ra√≠ces, comprobamos qu√© √°rbol es m√°s grande: el m√°s peque√±o acabar√° siendo el hijo, y reasignaremos su ra√≠z. Adem√°s, tenemos que actualizar el rango de la ra√≠z del √°rbol m√°s grande; su sub√°rbol ahora tambi√©n contendr√° todos los elementos de su nuevo hijo.

# Applications

Las aplicaciones de los conjuntos disjuntos son omnipresentes como jesucristo, hahaha, y la raz√≥n por la que se han estudiado a fondo es precisamente por el n√∫mero de casos en los que resultan √∫tiles, por ejemplo en las gr√°ficas

* Gr√°ficos: Componentes conectados 

	- En el caso de los grafos no dirigidos, existe un algoritmo sencillo que utiliza conjuntos disjuntos para llevar la cuenta de sus componentes conectados, es decir, las zonas del grafo que est√°n interconectadas.

	- Los componentes conectados se calculan normalmente utilizando la B√∫squeda por Profundidad (DFS), podemos utilizar un conjunto disjunto para realizar un seguimiento de los componentes mientras exploramos todas las aristas del grafo. 

	- Al final, cada partici√≥n de v√©rtices en disjointSet ser√° un componente conectado. Cabe destacar que este algoritmo no se puede utilizar para grafos dirigidos y componentes fuertemente conectados

* Graphs: Tambi√©n se ocupan en el algorithm de Kruskal para sacar el √°rbol generador minimo de una gr√°fica  minimum spanning tree

	Un √°rbol generador de un grafo no dirigido conexo G es un √°rbol cuyos nodos son los v√©rtices del grafo y cuyas aristas son un subconjunto de las aristas de G. 

	Y sabemos que si G es un grafo conexo, entonces tiene al menos un √°rbol de expansi√≥n y posiblemente muchos si este tambi√©n tiene ciclos. Y entre todos los √°rboles de expansi√≥n posibles, el √°rbol de expansi√≥n m√≠nima es aquel en el que la suma de los pesos de las aristas es m√≠nima.

	- (A) Ejemplo de un grafo con varios √°rboles de expansi√≥n, Un grafo no dirigido, conectado, que contiene ciclos. 
	- (B) Como el grafo tiene ciclos, hay varios √°rboles de expansi√≥n que cubren todos los nodos. Se muestran algunos ejemplos, cada uno de ellos seleccionando s√≥lo el conjunto m√°s peque√±o de aristas (las gruesas) que "abarcan" todos los v√©rtices. (
	- C) Para cada conjunto de aristas, se pueden obtener varios √°rboles, dependiendo de la ra√≠z del √°rbol y del orden de los hijos. (S√≥lo se muestran algunos ejemplos. Observe, no obstante, que no se limitan a √°rboles binarios).

	- /// El algoritmo de Kruskal est√° fuera del alcance de este libro. Aqu√≠ basta con decir que construye el MST de un grafo de la siguiente manera

		- Comenzando con cada v√©rtice en un conjunto de diferencia.
		- Manteniendo un conjunto disjunto de los v√©rtices del grafo.
		- Recorriendo las aristas del grafo en orden de peso creciente.
		- Para cada arista, si sus extremos no est√°n en la misma partici√≥n, fusionar sus componentes.
		- Si todos los v√©rtices pertenecen a la misma componente, parar.

* Clustering: Tambi√©n se puede ocupar en el clustering, este es el algoritmo de aprendizaje no supervisado m√°s utilizado. El problema es que queremos obtener una partici√≥n de un conjunto de puntos en unos diferentes subconjuntos, normalmente disjuntos.

	- Un ejemplo: el clustering jer√°rquico aglomerativo comienza con cada punto en su propio cluster (partici√≥n) y fusiona continuamente dos puntos (y sus clusters) hasta que todos los clusters se fusionan en uno; la figura de abajo a la izq muestra un ejemplo de c√≥mo funciona. 

		- El algoritmo mantiene un historial de este proceso, y es posible obtener una instant√°nea de los clusters creados en cualquiera de los pasos. El punto exacto en el que se toma esta instant√°nea se controla mediante unos pocos par√°metros y determina el resultado del algoritmo. 

* Unificaci√≥n: La unificaci√≥n es el proceso de resolver ecuaciones entre expresiones simb√≥licas. Una de las formas de resolver una ecuaci√≥n de este tipo es encontrar t√©rminos en ambos lados que sean equivalentes y eliminarlos de la ecuaci√≥n. Por supuesto, las estrategias de soluci√≥n dependen de las expresiones (t√©rminos) que pueden aparecer en la ecuaci√≥n y de c√≥mo se pueden comparar o cu√°ndo se consideran iguales. Por ejemplo, pueden evaluarse y considerarse iguales si tienen el mismo valor, o pueden ser simb√≥licos y considerarse iguales si son equivalentes, posiblemente netos de alguna sustituci√≥n de variables.

Resumen: 

La belleza de esta estructura(un conjunto disjunto) es que podemos construir soluciones cada vez m√°s complejas y eficientes para resolverlo, a√±adiendo peque√±os cambios incrementales.

A veces podemos conformarnos con una implementaci√≥n sub√≥ptima si es lo suficientemente eficiente y el rendimiento no es cr√≠tico.

Probablemente podr√≠amos conformarnos con la soluci√≥n ingenua de tiempo lineal, pero sabemos que es una parte tan fundamental de muchos algoritmos de grafos que debemos optimizarla al m√°ximo.

Conocemos un l√≠mite inferior te√≥rico para el tiempo de ejecuci√≥n de las operaciones de un conjunto disjunto, pero no sabemos si existe un algoritmo que se ejecute con ese l√≠mite, o incluso cualquier otro algoritmo m√°s r√°pido que los que conocemos.

La funci√≥n inversa de Ackermann, cuyo valor no ser√° mayor que 5 para cualquier n√∫mero entero que quepa en un ordenador, modela el orden de magnitud del tiempo de ejecuci√≥n de la operaci√≥n de fusi√≥n en conjuntos disjuntos. 

Fusionar dos subconjuntos requerir√°, por t√©rmino medio, s√≥lo cinco intercambios como m√°ximo.

----
‚å®Ô∏è with much :purple_heart: by [Jose-MPM](https://github.com/Jose-MPM) üòä‚å®Ô∏è